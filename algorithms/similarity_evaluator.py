"""
SimilarityEvaluator - åŸºäºä¸“å®¶è§„åˆ™çš„å…‰è°±è´¨é‡è¯„ä¼°å™¨
å®ç°Quality Scoreè®¡ç®—ã€æƒé‡è®¡ç®—ã€åŠ æƒç»Ÿè®¡æŒ‡æ ‡ç­‰åŠŸèƒ½
ä¸“é—¨ä¸ºDVPæ¶‚å±‚ç±»å‹ä¼˜åŒ–
"""

import numpy as np
import pandas as pd
from typing import Dict, Any, Tuple, Optional
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class SimilarityEvaluator:
    """
    å…‰è°±ç›¸ä¼¼æ€§è¯„ä¼°å™¨
    
    åŸºäºä¸“å®¶è§„åˆ™çš„å…‰è°±è´¨é‡è¯„ä¼°ç³»ç»Ÿï¼Œä¸“é—¨ç”¨äºDVPæ¶‚å±‚ç±»å‹çš„å…‰è°±åˆ†æ
    è®¡ç®—Quality Scoreï¼Œè¯„ä¼°å…‰è°±ä¸é¢„å®šä¹‰"é»„é‡‘æ ‡å‡†"çš„ç¬¦åˆç¨‹åº¦
    """
    
    def __init__(self, coating_name: str = "DVP"):
        """
        åˆå§‹åŒ–è¯„ä¼°å™¨
        
        Args:
            coating_name: æ¶‚å±‚åç§°ï¼Œç”¨äºé€‰æ‹©ç‰¹å®šçš„æƒé‡é…ç½®
        """
        self.coating_name = coating_name
        self.wavelengths = np.arange(380, 781, 5)  # 380-780nm, æ­¥é•¿5nm
        
        logger.info(f"SimilarityEvaluator åˆå§‹åŒ–å®Œæˆ [{coating_name}]")
        logger.info(f"æ³¢é•¿èŒƒå›´: {self.wavelengths.min()}-{self.wavelengths.max()}nm, å…±{len(self.wavelengths)}ä¸ªç‚¹")
    
    def evaluate(self, y1: np.ndarray, y2: np.ndarray, 
                 wavelengths: Optional[np.ndarray] = None,
                 weight_range: Tuple[int, int] = (400, 680),
                 coating_name: Optional[str] = None) -> Dict[str, Any]:
        """
        è¯„ä¼°ä¸¤ä¸ªå…‰è°±çš„ç›¸ä¼¼æ€§
        
        Args:
            y1: å®æ—¶ä¼ å…¥çš„å…‰è°±æ•°æ® (åå°„ç‡æ›²çº¿)
            y2: é¢„å­˜çš„"é»„é‡‘æ ‡å‡†"å…‰è°± (åå°„ç‡æ›²çº¿)
            wavelengths: å…‰è°±å¯¹åº”çš„æ³¢é•¿æ•°ç»„ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤æ³¢é•¿
            weight_range: æƒé‡è®¡ç®—çš„èŒƒå›´ (start, end)
            coating_name: æ¶‚å±‚åç§°ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨åˆå§‹åŒ–æ—¶çš„åç§°
            
        Returns:
            Dict[str, Any]: åŒ…å«æ‰€æœ‰è¯„ä¼°æŒ‡æ ‡çš„å­—å…¸
        """
        # å‚æ•°éªŒè¯
        if coating_name is None:
            coating_name = self.coating_name
            
        if wavelengths is None:
            wavelengths = self.wavelengths
        
        # æ•°æ®é•¿åº¦æ£€æŸ¥å’Œæˆªæ–­
        min_len = min(len(y1), len(y2), len(wavelengths))
        y1, y2, wavelengths = y1[:min_len], y2[:min_len], wavelengths[:min_len]
        
        logger.debug(f"æ•°æ®é•¿åº¦æ£€æŸ¥: y1={len(y1)}, y2={len(y2)}, wavelengths={len(wavelengths)}")
        
        # è®¡ç®—æƒé‡å‘é‡
        weights = self._calculate_weights(wavelengths, weight_range, coating_name)
        
        # è®¡ç®—åŠ æƒæŒ‡æ ‡
        weighted_pearson = self._weighted_pearson(y1, y2, weights)
        rmse = self._weighted_rmse(y1, y2, weights)
        
        # ç»¼åˆå¾—åˆ†è®¡ç®— (æ ¹æ®è§„æ ¼æ–‡æ¡£)
        # similarity_score = 0.3 * (1 + weighted_pearson) / 2 + 0.7 * (1 / (1 + rmse))
        # ä¿®æ­£ï¼šç¡®ä¿åœ¨ç†æƒ³æƒ…å†µä¸‹(pearson=1, rmse=0)å¾—åˆ°100%çš„åˆ†æ•°
        similarity_score = 0.3 * (1 + weighted_pearson) / 2 + 0.7 * (1 / (1 + rmse))
        
        # è½¬æ¢ä¸ºç™¾åˆ†æ¯”å½¢å¼
        similarity_score_percent = similarity_score * 100
        
        result = {
            "weighted_pearson": float(weighted_pearson),
            "rmse": float(rmse),
            "similarity_score": float(similarity_score),
            "similarity_score_percent": float(similarity_score_percent),
            "weights": weights,
            "metadata": {
                "coating_name": coating_name,
                "weight_range": weight_range,
                "data_points": len(y1),
                "wavelength_range": f"{wavelengths.min():.0f}-{wavelengths.max():.0f}nm"
            }
        }
        
        logger.debug(f"è¯„ä¼°å®Œæˆ: Quality Score = {similarity_score_percent:.2f}%")
        return result
    
    def _calculate_weights(self, wavelengths: np.ndarray, weight_range: Tuple[int, int], 
                          coating_name: str) -> np.ndarray:
        """
        è®¡ç®—æƒé‡å‘é‡
        
        æ ¹æ®æ¶‚å±‚ç±»å‹å’Œæ³¢é•¿èŒƒå›´ï¼Œä¸ºä¸åŒæ³¢æ®µåˆ†é…ä¸åŒçš„æƒé‡
        è¿™æ˜¯ä¸“å®¶çŸ¥è¯†çš„ç›´æ¥ä½“ç°
        
        Args:
            wavelengths: æ³¢é•¿æ•°ç»„
            weight_range: æƒé‡è®¡ç®—èŒƒå›´
            coating_name: æ¶‚å±‚åç§°
            
        Returns:
            np.ndarray: æƒé‡å‘é‡
        """
        weights = np.ones_like(wavelengths, dtype=np.float64)
        
        # åŸºç¡€æƒé‡: åœ¨æŒ‡å®šèŒƒå›´å†…æƒé‡ä¸º3
        mask = (wavelengths >= weight_range[0]) & (wavelengths <= weight_range[1])
        weights[mask] = 3.0
        
        logger.debug(f"åŸºç¡€æƒé‡è®¾ç½®: èŒƒå›´{weight_range[0]}-{weight_range[1]}nm, æƒé‡=3")
        
        # æ ¹æ®æ¶‚å±‚ç±»å‹è°ƒæ•´æƒé‡
        if coating_name == "DVS":
            # DVSæ¶‚å±‚æš‚æ— ç‰¹æ®Šè°ƒæ•´
            logger.debug("DVSæ¶‚å±‚: ä½¿ç”¨é»˜è®¤æƒé‡é…ç½®")
            
        elif coating_name == "DVP":
            # DVPæ¶‚å±‚: å¢å¼º400-550nmæ³¢æ®µçš„æƒé‡
            peak_mask = (wavelengths >= 400) & (wavelengths <= 550)
            weights[peak_mask] *= 1.5
            logger.debug("DVPæ¶‚å±‚: 400-550nmæ³¢æ®µæƒé‡å¢å¼º1.5å€")
            
        elif coating_name == "DVK":
            # DVKæ¶‚å±‚æš‚æ— ç‰¹æ®Šè°ƒæ•´
            logger.debug("DVKæ¶‚å±‚: ä½¿ç”¨é»˜è®¤æƒé‡é…ç½®")
            
        elif coating_name == "C2":
            # C2æ¶‚å±‚: å¤šä¸ªé‡ç‚¹æ³¢æ®µå¢å¼º
            # 445-465nm (è“è‰²å³°å€¼)
            peak_mask1 = (wavelengths >= 445) & (wavelengths <= 465)
            weights[peak_mask1] *= 20
            
            # 515-555nm (ç»¿è‰²å³°å€¼)
            peak_mask2 = (wavelengths >= 515) & (wavelengths <= 555)
            weights[peak_mask2] *= 30
            
            # 645-685nm (çº¢è‰²å³°å€¼)
            peak_mask3 = (wavelengths >= 645) & (wavelengths <= 685)
            weights[peak_mask3] *= 10
            
            logger.debug("C2æ¶‚å±‚: å¤šæ³¢æ®µæƒé‡å¢å¼º (è“è‰²20x, ç»¿è‰²30x, çº¢è‰²10x)")
            
        elif coating_name == "BPCN_CX":
            # BPCN_CXæ¶‚å±‚: 400-500nmæ³¢æ®µå¢å¼º
            peak_mask = (wavelengths >= 400) & (wavelengths <= 500)
            weights[peak_mask] *= 1.5
            logger.debug("BPCN_CXæ¶‚å±‚: 400-500nmæ³¢æ®µæƒé‡å¢å¼º1.5å€")
            
        elif coating_name == "BPCN_CC":
            # BPCN_CCæ¶‚å±‚: 400-500nmæ³¢æ®µå¢å¼º
            peak_mask = (wavelengths >= 400) & (wavelengths <= 500)
            weights[peak_mask] *= 1.5
            logger.debug("BPCN_CCæ¶‚å±‚: 400-500nmæ³¢æ®µæƒé‡å¢å¼º1.5å€")
            
        elif coating_name == "DVG":
            # DVGæ¶‚å±‚: 400-500nmæ³¢æ®µå¢å¼º
            peak_mask = (wavelengths >= 400) & (wavelengths <= 500)
            weights[peak_mask] *= 1.5
            logger.debug("DVGæ¶‚å±‚: 400-500nmæ³¢æ®µæƒé‡å¢å¼º1.5å€")
        
        # æƒé‡ç»Ÿè®¡ä¿¡æ¯
        logger.debug(f"æƒé‡ç»Ÿè®¡: min={weights.min():.2f}, max={weights.max():.2f}, mean={weights.mean():.2f}")
        
        return weights
    
    def _weighted_pearson(self, y1: np.ndarray, y2: np.ndarray, weights: np.ndarray) -> float:
        """
        è®¡ç®—åŠ æƒçš®å°”é€Šç›¸å…³ç³»æ•°
        
        Args:
            y1: ç¬¬ä¸€ä¸ªå…‰è°±æ•°ç»„
            y2: ç¬¬äºŒä¸ªå…‰è°±æ•°ç»„
            weights: æƒé‡æ•°ç»„
            
        Returns:
            float: åŠ æƒçš®å°”é€Šç›¸å…³ç³»æ•° (-1 åˆ° 1)
        """
        # è®¡ç®—åŠ æƒå‡å€¼
        mean_y1 = np.average(y1, weights=weights)
        mean_y2 = np.average(y2, weights=weights)
        
        # è®¡ç®—åŠ æƒåæ–¹å·®å’Œæ–¹å·®
        numerator = np.sum(weights * (y1 - mean_y1) * (y2 - mean_y2))
        denom_y1 = np.sqrt(np.sum(weights * (y1 - mean_y1) ** 2))
        denom_y2 = np.sqrt(np.sum(weights * (y2 - mean_y2) ** 2))
        
        # é¿å…é™¤é›¶é”™è¯¯
        denominator = denom_y1 * denom_y2
        if denominator == 0:
            logger.warning("åŠ æƒæ–¹å·®ä¸ºé›¶ï¼Œè¿”å›ç›¸å…³ç³»æ•°0")
            return 0.0
        
        correlation = numerator / denominator
        
        logger.debug(f"åŠ æƒçš®å°”é€Šç›¸å…³ç³»æ•°: {correlation:.4f}")
        return float(correlation)
    
    def _weighted_rmse(self, y1: np.ndarray, y2: np.ndarray, weights: np.ndarray) -> float:
        """
        è®¡ç®—åŠ æƒå‡æ–¹æ ¹è¯¯å·®
        
        Args:
            y1: ç¬¬ä¸€ä¸ªå…‰è°±æ•°ç»„
            y2: ç¬¬äºŒä¸ªå…‰è°±æ•°ç»„
            weights: æƒé‡æ•°ç»„
            
        Returns:
            float: åŠ æƒRMSE
        """
        # è®¡ç®—åŠ æƒå·®å€¼çš„å¹³æ–¹
        weighted_diff_sq = weights * (y1 - y2) ** 2
        
        # è®¡ç®—åŠ æƒRMSE
        rmse = np.sqrt(np.sum(weighted_diff_sq) / np.sum(weights))
        
        logger.debug(f"åŠ æƒRMSE: {rmse:.4f}")
        return float(rmse)
    
    def get_quality_score_threshold(self, coating_name: str = None, 
                                   quality_level: str = "good") -> float:
        """
        è·å–è´¨é‡åˆ†æ•°é˜ˆå€¼
        
        Args:
            coating_name: æ¶‚å±‚åç§°
            quality_level: è´¨é‡æ°´å¹³ ("excellent", "good", "acceptable", "poor")
            
        Returns:
            float: è´¨é‡åˆ†æ•°é˜ˆå€¼ (0-100)
        """
        if coating_name is None:
            coating_name = self.coating_name
            
        # æ ¹æ®æ¶‚å±‚ç±»å‹å’Œè´¨é‡æ°´å¹³å®šä¹‰é˜ˆå€¼
        thresholds = {
            "DVP": {
                "excellent": 95.0,
                "good": 90.0,
                "acceptable": 85.0,
                "poor": 80.0
            },
            "default": {
                "excellent": 95.0,
                "good": 90.0,
                "acceptable": 85.0,
                "poor": 80.0
            }
        }
        
        coating_thresholds = thresholds.get(coating_name, thresholds["default"])
        threshold = coating_thresholds.get(quality_level, coating_thresholds["good"])
        
        logger.debug(f"è´¨é‡é˜ˆå€¼ [{coating_name} - {quality_level}]: {threshold}%")
        return threshold
    
    def batch_evaluate(self, spectra_list: list, golden_standard: np.ndarray,
                      wavelengths: Optional[np.ndarray] = None,
                      coating_name: Optional[str] = None) -> pd.DataFrame:
        """
        æ‰¹é‡è¯„ä¼°å¤šä¸ªå…‰è°±
        
        Args:
            spectra_list: å…‰è°±æ•°æ®åˆ—è¡¨
            golden_standard: é»„é‡‘æ ‡å‡†å…‰è°±
            wavelengths: æ³¢é•¿æ•°ç»„
            coating_name: æ¶‚å±‚åç§°
            
        Returns:
            pd.DataFrame: è¯„ä¼°ç»“æœDataFrame
        """
        if wavelengths is None:
            wavelengths = self.wavelengths
            
        if coating_name is None:
            coating_name = self.coating_name
        
        results = []
        
        for i, spectrum in enumerate(spectra_list):
            try:
                result = self.evaluate(spectrum, golden_standard, wavelengths, coating_name=coating_name)
                result['spectrum_id'] = i
                results.append(result)
            except Exception as e:
                logger.error(f"å…‰è°± {i} è¯„ä¼°å¤±è´¥: {e}")
                results.append({
                    'spectrum_id': i,
                    'weighted_pearson': np.nan,
                    'rmse': np.nan,
                    'similarity_score': np.nan,
                    'similarity_score_percent': np.nan,
                    'error': str(e)
                })
        
        # è½¬æ¢ä¸ºDataFrame
        df_results = pd.DataFrame(results)
        
        logger.info(f"æ‰¹é‡è¯„ä¼°å®Œæˆ: {len(spectra_list)} ä¸ªå…‰è°±")
        return df_results
    
    def get_weight_visualization_data(self, wavelengths: Optional[np.ndarray] = None,
                                    coating_name: Optional[str] = None) -> Dict[str, Any]:
        """
        è·å–æƒé‡å¯è§†åŒ–æ•°æ®
        
        Args:
            wavelengths: æ³¢é•¿æ•°ç»„
            coating_name: æ¶‚å±‚åç§°
            
        Returns:
            Dict[str, Any]: å¯è§†åŒ–æ•°æ®
        """
        if wavelengths is None:
            wavelengths = self.wavelengths
            
        if coating_name is None:
            coating_name = self.coating_name
        
        weights = self._calculate_weights(wavelengths, (400, 680), coating_name)
        
        return {
            'wavelengths': wavelengths,
            'weights': weights,
            'coating_name': coating_name,
            'weight_stats': {
                'min': float(weights.min()),
                'max': float(weights.max()),
                'mean': float(weights.mean()),
                'std': float(weights.std())
            }
        }

# æµ‹è¯•ä»£ç 
if __name__ == "__main__":
    # åˆ›å»ºè¯„ä¼°å™¨
    evaluator = SimilarityEvaluator("DVP")
    
    # åŠ è½½å¤„ç†åçš„DVPæ•°æ®
    data = np.load("/workspace/code/spectrum_anomaly_detection/data/dvp_processed_data.npz")
    wavelengths = data['wavelengths']
    dvp_standard = data['dvp_values']
    
    print("=" * 60)
    print("SimilarityEvaluator æµ‹è¯•")
    print("=" * 60)
    
    # æµ‹è¯•1: ç›¸åŒå…‰è°±çš„è¯„ä¼°ï¼ˆåº”è¯¥å¾—åˆ°æ¥è¿‘100%çš„åˆ†æ•°ï¼‰
    print("\næµ‹è¯•1: ç›¸åŒå…‰è°±è¯„ä¼°")
    result1 = evaluator.evaluate(dvp_standard, dvp_standard, wavelengths, coating_name="DVP")
    print(f"Quality Score: {result1['similarity_score_percent']:.2f}%")
    print(f"åŠ æƒçš®å°”é€Šç›¸å…³ç³»æ•°: {result1['weighted_pearson']:.4f}")
    print(f"åŠ æƒRMSE: {result1['rmse']:.6f}")
    
    # æµ‹è¯•2: æ·»åŠ å™ªå£°çš„å…‰è°±è¯„ä¼°
    print("\næµ‹è¯•2: å™ªå£°å…‰è°±è¯„ä¼°")
    noise_level = 0.1
    noisy_spectrum = dvp_standard + np.random.normal(0, noise_level, len(dvp_standard))
    result2 = evaluator.evaluate(noisy_spectrum, dvp_standard, wavelengths, coating_name="DVP")
    print(f"Quality Score: {result2['similarity_score_percent']:.2f}%")
    print(f"åŠ æƒçš®å°”é€Šç›¸å…³ç³»æ•°: {result2['weighted_pearson']:.4f}")
    print(f"åŠ æƒRMSE: {result2['rmse']:.6f}")
    
    # æµ‹è¯•3: æƒé‡å¯è§†åŒ–æ•°æ®
    print("\næµ‹è¯•3: æƒé‡åˆ†æ")
    weight_data = evaluator.get_weight_visualization_data(wavelengths, "DVP")
    print(f"æƒé‡èŒƒå›´: {weight_data['weight_stats']['min']:.2f} - {weight_data['weight_stats']['max']:.2f}")
    print(f"æƒé‡å‡å€¼: {weight_data['weight_stats']['mean']:.2f}")
    
    # æµ‹è¯•4: è´¨é‡é˜ˆå€¼
    print("\næµ‹è¯•4: è´¨é‡é˜ˆå€¼")
    thresholds = {
        'excellent': evaluator.get_quality_score_threshold("DVP", "excellent"),
        'good': evaluator.get_quality_score_threshold("DVP", "good"),
        'acceptable': evaluator.get_quality_score_threshold("DVP", "acceptable"),
        'poor': evaluator.get_quality_score_threshold("DVP", "poor")
    }
    print("DVPæ¶‚å±‚è´¨é‡é˜ˆå€¼:")
    for level, threshold in thresholds.items():
        print(f"  {level}: {threshold}%")
    
    print("\nğŸ‰ SimilarityEvaluator æµ‹è¯•å®Œæˆï¼")